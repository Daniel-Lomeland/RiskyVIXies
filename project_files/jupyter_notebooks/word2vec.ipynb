{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "import pprint\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = '../../../../../APIKeys/API.yaml'\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as config_file:\n",
    "    config = yaml.load(config_file)\n",
    "\n",
    "PLOTLY_USERNAME = config[\"plotly\"][\"PLOTLY_USERNAME\"]\n",
    "PLOTLY_API_KEY = config[\"plotly\"][\"PLOTLY_API_KEY\"]\n",
    "\n",
    "plotly.tools.set_credentials_file(username = PLOTLY_USERNAME, api_key = PLOTLY_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Lead Paragraph</th>\n",
       "      <th>Main Headline</th>\n",
       "      <th>Print Headline</th>\n",
       "      <th>Seo Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2016-10-14T04:00:00+0000</td>\n",
       "      <td>The Business Roundtable has strongly endorsed ...</td>\n",
       "      <td>The Business Roundtable has strongly endorsed ...</td>\n",
       "      <td>Corporate Board Diversity Gets Push From Busin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2017-05-15T07:21:08+0000</td>\n",
       "      <td>Regulations put in after the 2008 crisis have ...</td>\n",
       "      <td>Regulations put in after the 2008 crisis have ...</td>\n",
       "      <td>To Spur Small Business, First Free the Banks</td>\n",
       "      <td>To Grow, First Free The Banks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2017-08-28T16:33:11+0000</td>\n",
       "      <td>Emails show that Felix Sater promised to get V...</td>\n",
       "      <td>Emails show that Felix Sater promised to get V...</td>\n",
       "      <td>Trump Associate Boasted That Moscow Business D...</td>\n",
       "      <td>Trump Associate Boasted in Email Of Ties to Putin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>2019-01-01T10:00:06+0000</td>\n",
       "      <td>Changing your approach to traveling can go a l...</td>\n",
       "      <td>Changing your approach to traveling can go a l...</td>\n",
       "      <td>Three New Year’s Resolutions for Better Travel...</td>\n",
       "      <td>Three Resolutions For the New Year</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2019-01-01T10:00:07+0000</td>\n",
       "      <td>“Homecoming,” “Dirty John” and “Lore” are just...</td>\n",
       "      <td>“Homecoming,” “Dirty John” and “Lore” are just...</td>\n",
       "      <td>In the Race for Content, Hollywood Is Buying U...</td>\n",
       "      <td>From Earbud To Screen: Studios Vie For Podcasts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Published  \\\n",
       "1176  2016-10-14T04:00:00+0000   \n",
       "1171  2017-05-15T07:21:08+0000   \n",
       "1178  2017-08-28T16:33:11+0000   \n",
       "1166  2019-01-01T10:00:06+0000   \n",
       "468   2019-01-01T10:00:07+0000   \n",
       "\n",
       "                                                Snippet  \\\n",
       "1176  The Business Roundtable has strongly endorsed ...   \n",
       "1171  Regulations put in after the 2008 crisis have ...   \n",
       "1178  Emails show that Felix Sater promised to get V...   \n",
       "1166  Changing your approach to traveling can go a l...   \n",
       "468   “Homecoming,” “Dirty John” and “Lore” are just...   \n",
       "\n",
       "                                         Lead Paragraph  \\\n",
       "1176  The Business Roundtable has strongly endorsed ...   \n",
       "1171  Regulations put in after the 2008 crisis have ...   \n",
       "1178  Emails show that Felix Sater promised to get V...   \n",
       "1166  Changing your approach to traveling can go a l...   \n",
       "468   “Homecoming,” “Dirty John” and “Lore” are just...   \n",
       "\n",
       "                                          Main Headline  \\\n",
       "1176  Corporate Board Diversity Gets Push From Busin...   \n",
       "1171       To Spur Small Business, First Free the Banks   \n",
       "1178  Trump Associate Boasted That Moscow Business D...   \n",
       "1166  Three New Year’s Resolutions for Better Travel...   \n",
       "468   In the Race for Content, Hollywood Is Buying U...   \n",
       "\n",
       "                                         Print Headline  Seo Headline  \n",
       "1176                                                NaN           NaN  \n",
       "1171                      To Grow, First Free The Banks           NaN  \n",
       "1178  Trump Associate Boasted in Email Of Ties to Putin           NaN  \n",
       "1166                 Three Resolutions For the New Year           NaN  \n",
       "468     From Earbud To Screen: Studios Vie For Podcasts           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data = pd.read_csv('../../business_news.csv')\n",
    "main_data = main_data.sort_values(by = \"Published\")\n",
    "\n",
    "news_data = main_data[[\"Snippet\", \"Lead Paragraph\", \"Main Headline\"]]\n",
    "main_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Business Roundtable has strongly endorsed a link between board diversity and board effectiveness and the creation of long-term shareholder value.', 'The Business Roundtable has strongly endorsed a link between board diversity and board effectiveness and the creation of long-term shareholder value.', 'Corporate Board Diversity Gets Push From Business Leaders']\n"
     ]
    }
   ],
   "source": [
    "def list_prep(rows_to_list):\n",
    "    news_list = rows_to_list.values.tolist()\n",
    "    return(news_list)\n",
    "    \n",
    "list_of_lists = list_prep(news_data)\n",
    "print(list_of_lists[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'roundtable', 'strongly', 'endorsed', 'link', 'board', 'diversity', 'board', 'effectiveness', 'creation', 'shareholder', 'value', 'business', 'roundtable', 'strongly', 'endorsed', 'link', 'board', 'diversity', 'board', 'effectiveness', 'creation', 'shareholder', 'value', 'corporate', 'board', 'diversity', 'gets', 'push', 'business', 'leaders']\n"
     ]
    }
   ],
   "source": [
    "def word_prep(list_lists):\n",
    "    big_string = \"\"\n",
    "\n",
    "    for title in list_lists:\n",
    "    #     Splitting titles into list of words\n",
    "        variable = title.split(\" \")\n",
    "    #     print(variable)\n",
    "\n",
    "    #     v = words\n",
    "    #     variable = list of words\n",
    "        for v in variable:\n",
    "            big_string = big_string + \" \" + v\n",
    "\n",
    "    #     big_title_string = ' '.join((str(v) for v in variable))\n",
    "\n",
    "    tokens = word_tokenize(big_string)\n",
    "\n",
    "    # Remove non-alphabetic tokens, such as punctuation\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Filter out stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "\n",
    "    # Print first 10 words\n",
    "    return(words)\n",
    "\n",
    "\n",
    "    # print(tokens)\n",
    "word_list = []\n",
    "for list in list_of_lists:\n",
    "    words = word_prep(list)\n",
    "    word_list.append(words)\n",
    "print(word_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load word2vec model (trained on an enormous Google corpus)\n",
    "model = gensim.models.KeyedVectors.\\\n",
    "load_word2vec_format('../resources/model/GoogleNews-vectors-negative300.bin', binary = True) \n",
    "\n",
    "# Check dimension of word vectors\n",
    "model.vector_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_2_vec(words):\n",
    "    vector_list = []\n",
    "    words_filtered = []\n",
    "    # Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "    vector_list.extend([model[word] for word in words if word in model.vocab])\n",
    "#     return(vector_list)\n",
    "    # Create a list of the words corresponding to these vectors\n",
    "    words_filtered.extend([word for word in words if word in model.vocab])\n",
    "#     return(words_filtered)\n",
    "    # Zip the words together with their vector representations\n",
    "    word_vec_zip = zip(words_filtered, vector_list)\n",
    "    \n",
    "    # Cast to a dict so we can turn it into a dataframe\n",
    "    word_vec_dict = dict(word_vec_zip)\n",
    "    return(word_vec_dict)\n",
    "    \n",
    "\n",
    "\n",
    "dataframe_dict_list = []\n",
    "for list in word_list:\n",
    "    df = word_2_vec(list)\n",
    "#     print(z)\n",
    "    dataframe_dict_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>roundtable</th>\n",
       "      <th>strongly</th>\n",
       "      <th>endorsed</th>\n",
       "      <th>link</th>\n",
       "      <th>board</th>\n",
       "      <th>diversity</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>creation</th>\n",
       "      <th>shareholder</th>\n",
       "      <th>value</th>\n",
       "      <th>corporate</th>\n",
       "      <th>gets</th>\n",
       "      <th>push</th>\n",
       "      <th>leaders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010376</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.058105</td>\n",
       "      <td>-0.235352</td>\n",
       "      <td>-0.077148</td>\n",
       "      <td>-0.144531</td>\n",
       "      <td>-0.214844</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>-0.020874</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>-0.066895</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.051025</td>\n",
       "      <td>0.089355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.048584</td>\n",
       "      <td>0.135742</td>\n",
       "      <td>-0.032227</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>-0.077148</td>\n",
       "      <td>-0.259766</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.124512</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.168945</td>\n",
       "      <td>0.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.126953</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>-0.028198</td>\n",
       "      <td>0.205078</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>-0.016113</td>\n",
       "      <td>0.142578</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>-0.084473</td>\n",
       "      <td>-0.017334</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.231445</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.131836</td>\n",
       "      <td>0.163086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.108887</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>-0.055420</td>\n",
       "      <td>-0.125977</td>\n",
       "      <td>0.062256</td>\n",
       "      <td>-0.010742</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>-0.107910</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>-0.105469</td>\n",
       "      <td>0.233398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>-0.102051</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>-0.099121</td>\n",
       "      <td>-0.012817</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>-0.024292</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>-0.109863</td>\n",
       "      <td>-0.050293</td>\n",
       "      <td>-0.049805</td>\n",
       "      <td>-0.142578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business  roundtable  strongly  endorsed      link     board  diversity  \\\n",
       "0  0.010376   -0.308594 -0.058105 -0.235352 -0.077148 -0.144531  -0.214844   \n",
       "1 -0.048584    0.135742 -0.032227 -0.147461 -0.077148 -0.259766   0.166016   \n",
       "2 -0.126953   -0.115234 -0.028198  0.205078 -0.036865 -0.016113   0.142578   \n",
       "3 -0.108887    0.087891 -0.055420 -0.125977  0.062256 -0.010742   0.118652   \n",
       "4  0.030273    0.251953 -0.102051 -0.218750 -0.099121 -0.012817  -0.003220   \n",
       "\n",
       "   effectiveness  creation  shareholder     value  corporate      gets  \\\n",
       "0       0.109863 -0.020874     0.070312  0.079590  -0.066895  0.075195   \n",
       "1       0.124512 -0.032715     0.193359  0.018799   0.059082  0.022827   \n",
       "2      -0.001884 -0.084473    -0.017334  0.109375  -0.231445 -0.125000   \n",
       "3       0.012817  0.012878    -0.107910  0.018677   0.101562  0.007935   \n",
       "4      -0.024292  0.048340     0.146484 -0.114258  -0.109863 -0.050293   \n",
       "\n",
       "       push   leaders  \n",
       "0  0.051025  0.089355  \n",
       "1  0.168945  0.153320  \n",
       "2 -0.131836  0.163086  \n",
       "3 -0.105469  0.233398  \n",
       "4 -0.049805 -0.142578  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe_list = []\n",
    "for dataframe in range(len(dataframe_dict_list)):\n",
    "    df = pd.DataFrame.from_dict(dataframe_dict_list[dataframe])\n",
    "    dataframe_list.append(df)\n",
    "# df.shape\n",
    "dataframe_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.042708\n",
      "1    0.029647\n",
      "2   -0.019681\n",
      "3    0.009444\n",
      "4   -0.030000\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "def row_summation(dataframe_list):\n",
    "    summation_list = []\n",
    "    for dataframe in dataframe_list:\n",
    "    #     print(dataframe)\n",
    "        total_columns = len(dataframe.columns)\n",
    "    #     print(total_columns)\n",
    "        sums = dataframe.sum(axis = 1, skipna = True)\n",
    "    #     print(sums)\n",
    "        summation = sums/total_columns\n",
    "        summation_list.append(summation)\n",
    "    return summation_list\n",
    "\n",
    "    \n",
    "summation_series = row_summation(dataframe_list)\n",
    "print(summation_series[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_list = main_data['Published'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-14T04:00:00+0000</th>\n",
       "      <td>-0.042708</td>\n",
       "      <td>0.029647</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>-0.058390</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>-0.037046</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>0.091940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107121</td>\n",
       "      <td>-0.026034</td>\n",
       "      <td>-0.079626</td>\n",
       "      <td>0.095634</td>\n",
       "      <td>0.015284</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.064372</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>-0.071216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-15T07:21:08+0000</th>\n",
       "      <td>0.028475</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.081352</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>-0.142033</td>\n",
       "      <td>-0.019288</td>\n",
       "      <td>-0.052985</td>\n",
       "      <td>0.143840</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146977</td>\n",
       "      <td>0.012309</td>\n",
       "      <td>-0.083553</td>\n",
       "      <td>-0.017334</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>-0.095197</td>\n",
       "      <td>0.040135</td>\n",
       "      <td>0.063836</td>\n",
       "      <td>-0.102547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28T16:33:11+0000</th>\n",
       "      <td>-0.002913</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>-0.019647</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>-0.048486</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>0.035422</td>\n",
       "      <td>-0.023903</td>\n",
       "      <td>0.077841</td>\n",
       "      <td>0.049966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>-0.063055</td>\n",
       "      <td>-0.010825</td>\n",
       "      <td>-0.048286</td>\n",
       "      <td>-0.086072</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>-0.077390</td>\n",
       "      <td>0.039180</td>\n",
       "      <td>0.016693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01T10:00:06+0000</th>\n",
       "      <td>-0.020165</td>\n",
       "      <td>0.114699</td>\n",
       "      <td>-0.038919</td>\n",
       "      <td>0.149319</td>\n",
       "      <td>-0.029073</td>\n",
       "      <td>-0.021098</td>\n",
       "      <td>-0.019813</td>\n",
       "      <td>-0.087023</td>\n",
       "      <td>0.072137</td>\n",
       "      <td>0.042570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100715</td>\n",
       "      <td>0.069874</td>\n",
       "      <td>-0.060326</td>\n",
       "      <td>0.026296</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.040070</td>\n",
       "      <td>0.069238</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.066581</td>\n",
       "      <td>-0.048204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01T10:00:07+0000</th>\n",
       "      <td>0.062875</td>\n",
       "      <td>0.052707</td>\n",
       "      <td>-0.067801</td>\n",
       "      <td>0.108041</td>\n",
       "      <td>-0.057408</td>\n",
       "      <td>-0.058799</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>-0.099071</td>\n",
       "      <td>0.143119</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027152</td>\n",
       "      <td>0.045913</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>0.088440</td>\n",
       "      <td>-0.048104</td>\n",
       "      <td>-0.020682</td>\n",
       "      <td>-0.091771</td>\n",
       "      <td>-0.010306</td>\n",
       "      <td>0.050415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1         2         3         4    \\\n",
       "2016-10-14T04:00:00+0000 -0.042708  0.029647 -0.019681  0.009444 -0.030000   \n",
       "2017-05-15T07:21:08+0000  0.028475  0.095679  0.023912  0.081352 -0.035714   \n",
       "2017-08-28T16:33:11+0000 -0.002913  0.007083 -0.019647  0.050519 -0.048486   \n",
       "2019-01-01T10:00:06+0000 -0.020165  0.114699 -0.038919  0.149319 -0.029073   \n",
       "2019-01-01T10:00:07+0000  0.062875  0.052707 -0.067801  0.108041 -0.057408   \n",
       "\n",
       "                               5         6         7         8         9    \\\n",
       "2016-10-14T04:00:00+0000 -0.058390  0.025602 -0.037046  0.146306  0.091940   \n",
       "2017-05-15T07:21:08+0000 -0.142033 -0.019288 -0.052985  0.143840  0.017806   \n",
       "2017-08-28T16:33:11+0000 -0.015724  0.035422 -0.023903  0.077841  0.049966   \n",
       "2019-01-01T10:00:06+0000 -0.021098 -0.019813 -0.087023  0.072137  0.042570   \n",
       "2019-01-01T10:00:07+0000 -0.058799  0.003148 -0.099071  0.143119  0.078700   \n",
       "\n",
       "                            ...          290       291       292       293  \\\n",
       "2016-10-14T04:00:00+0000    ...    -0.107121 -0.026034 -0.079626  0.095634   \n",
       "2017-05-15T07:21:08+0000    ...    -0.146977  0.012309 -0.083553 -0.017334   \n",
       "2017-08-28T16:33:11+0000    ...     0.015891  0.018854 -0.063055 -0.010825   \n",
       "2019-01-01T10:00:06+0000    ...    -0.100715  0.069874 -0.060326  0.026296   \n",
       "2019-01-01T10:00:07+0000    ...    -0.027152  0.045913 -0.095576  0.008519   \n",
       "\n",
       "                               294       295       296       297       298  \\\n",
       "2016-10-14T04:00:00+0000  0.015284  0.013509  0.064372  0.004792  0.014158   \n",
       "2017-05-15T07:21:08+0000  0.005087  0.021395 -0.095197  0.040135  0.063836   \n",
       "2017-08-28T16:33:11+0000 -0.048286 -0.086072  0.034598 -0.077390  0.039180   \n",
       "2019-01-01T10:00:06+0000  0.004639  0.040070  0.069238  0.006884  0.066581   \n",
       "2019-01-01T10:00:07+0000  0.088440 -0.048104 -0.020682 -0.091771 -0.010306   \n",
       "\n",
       "                               299  \n",
       "2016-10-14T04:00:00+0000 -0.071216  \n",
       "2017-05-15T07:21:08+0000 -0.102547  \n",
       "2017-08-28T16:33:11+0000  0.016693  \n",
       "2019-01-01T10:00:06+0000 -0.048204  \n",
       "2019-01-01T10:00:07+0000  0.050415  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation_dict = {}\n",
    "published_index = 0\n",
    "for series in summation_series:\n",
    "    summation_dict.update({published_list[published_index]: series})\n",
    "    published_index += 1\n",
    "    \n",
    "summation_df = pd.DataFrame(summation_dict)\n",
    "summation_df = summation_df.T\n",
    "summation_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_df.to_csv(\"../resources/news/business_news_word2vec.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components = 2, init = 'random', random_state = 10, perplexity = 100)\n",
    "\n",
    "# Use only 400 rows to shorten processing time\n",
    "tsne_df = tsne.fit_transform(df[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11.7, 8.27))\n",
    "sns.scatterplot(tsne_df[:, 0], tsne_df[:, 1], alpha = 0.5)\n",
    "\n",
    "# Second plot: Import adjustText, initialize list of texts\n",
    "from adjustText import adjust_text\n",
    "texts = []\n",
    "words_to_plot = list(np.arange(0, 400, 10))\n",
    "\n",
    "# Append words to list\n",
    "for word in words_to_plot:\n",
    "    texts.append(plt.text(tsne_df[word, 0], tsne_df[word, 1], df.index[word], fontsize = 14))\n",
    "    \n",
    "# Plot text using adjust_text (because overlapping text is hard to read)\n",
    "adjust_text(texts, force_points = 0.4, force_text = 0.4, \n",
    "            expand_points = (2,1), expand_text = (1,2),\n",
    "            arrowprops = dict(arrowstyle = \"-\", color = 'black', lw = 0.5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = {\n",
    "    'data': [\n",
    "  \t\t{\n",
    "  \t\t\t'x': tsne_df[:, 0], \n",
    "        \t'y': tsne_df[:, 1], \n",
    "        \t'text': df.index,\n",
    "            \"mode\": \"markers\"\n",
    "        }]}   \n",
    "\n",
    "py.plot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in model.vocab]\n",
    "    return np.mean(model[doc], axis=0)\n",
    "\n",
    "# Our earlier preprocessing was done when we were dealing only with word vectors\n",
    "# Here, we need each document to remain a document \n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] \n",
    "    return doc\n",
    "\n",
    "# Function that will help us drop documents that have no word vectors in word2vec\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)\n",
    "\n",
    "# Filter out documents\n",
    "def filter_docs(corpus, texts, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus and texts given the function condition_on_doc which takes a doc. The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    if texts is not None:\n",
    "        texts = [text for (text, doc) in zip(texts, corpus)\n",
    "                 if condition_on_doc(doc)]\n",
    "\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the corpus\n",
    "corpus = [preprocess(title) for title in titles_list]\n",
    "\n",
    "# Remove docs that don't include any words in W2V's vocab\n",
    "corpus, titles_list = filter_docs(corpus, titles_list, lambda doc: has_vector_representation(model, doc))\n",
    "\n",
    "# Filter out any empty docs\n",
    "corpus, titles_list = filter_docs(corpus, titles_list, lambda doc: (len(doc) != 0))\n",
    "x = []\n",
    "for doc in corpus: # append the vector for each document\n",
    "    x.append(document_vector(model, doc))\n",
    "    \n",
    "X = np.array(x) # list to array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components = 2, init = 'random', random_state = 10, perplexity = 100)\n",
    "\n",
    "# Again use only 400 rows to shorten processing time\n",
    "tsne_df = tsne.fit_transform(X[:400])\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.scatterplot(tsne_df[:, 0], tsne_df[:, 1], alpha = 0.5)\n",
    "\n",
    "texts = []\n",
    "titles_to_plot = list(np.arange(0, 400, 40)) # plots every 40th title in first 400 titles\n",
    "\n",
    "# Append words to list\n",
    "for title in titles_to_plot:\n",
    "    texts.append(plt.text(tsne_df[title, 0], tsne_df[title, 1], titles_list[title], fontsize = 14))\n",
    "    \n",
    "# Plot text using adjust_text\n",
    "adjust_text(texts, force_points = 0.4, force_text = 0.4, \n",
    "            expand_points = (2,1), expand_text = (1,2),\n",
    "            arrowprops = dict(arrowstyle = \"-\", color = 'black', lw = 0.5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titles_to_plot)\n",
    "type(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = {\n",
    "    'data': [\n",
    "  \t\t{\n",
    "  \t\t\t'x': tsne_df[:, 0], \n",
    "        \t'y': tsne_df[:, 1], \n",
    "        \t'text': titles_list[title],\n",
    "            \"mode\": \"markers\"\n",
    "        }]}   \n",
    "\n",
    "py.plot(fig2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
