{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "import pprint\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Lead Paragraph</th>\n",
       "      <th>Main Headline</th>\n",
       "      <th>Print Headline</th>\n",
       "      <th>Seo Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2019-01-01T07:30:05+0000</td>\n",
       "      <td>Underperforming media deals have left the conf...</td>\n",
       "      <td>Underperforming media deals have left the conf...</td>\n",
       "      <td>Another Season Comes and Goes While Pac-12 Str...</td>\n",
       "      <td>A Power Conference’s Declining Clout</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2019-01-01T14:00:04+0000</td>\n",
       "      <td>Recent commercial real estate transactions in ...</td>\n",
       "      <td>Recent commercial real estate transactions in ...</td>\n",
       "      <td>Recent Commercial Real Estate Transactions</td>\n",
       "      <td>Transactions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>2019-01-01T17:47:14+0000</td>\n",
       "      <td>Skeptical reporting has still been too favorable.</td>\n",
       "      <td>Skeptical reporting has still been too favorable.</td>\n",
       "      <td>The Trump Tax Cut: Even Worse Than You’ve Heard</td>\n",
       "      <td>The Trump Tax Cut: Even Worse Than You’ve Heard</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2019-01-01T21:21:40+0000</td>\n",
       "      <td>The episode of “Patriot Act With Hasan Minhaj,...</td>\n",
       "      <td>The episode of “Patriot Act With Hasan Minhaj,...</td>\n",
       "      <td>Netflix Blocks Show in Saudi Arabia Critical o...</td>\n",
       "      <td>Netflix Blocks Show in Saudi Arabia Critical o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2019-01-02T07:00:00+0000</td>\n",
       "      <td>This word has appeared in 10 articles on NYTim...</td>\n",
       "      <td>This word has appeared in 10 articles on NYTim...</td>\n",
       "      <td>Word + Quiz: agog</td>\n",
       "      <td>Word + Quiz: agog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Published  \\\n",
       "977  2019-01-01T07:30:05+0000   \n",
       "674  2019-01-01T14:00:04+0000   \n",
       "879  2019-01-01T17:47:14+0000   \n",
       "307  2019-01-01T21:21:40+0000   \n",
       "357  2019-01-02T07:00:00+0000   \n",
       "\n",
       "                                               Snippet  \\\n",
       "977  Underperforming media deals have left the conf...   \n",
       "674  Recent commercial real estate transactions in ...   \n",
       "879  Skeptical reporting has still been too favorable.   \n",
       "307  The episode of “Patriot Act With Hasan Minhaj,...   \n",
       "357  This word has appeared in 10 articles on NYTim...   \n",
       "\n",
       "                                        Lead Paragraph  \\\n",
       "977  Underperforming media deals have left the conf...   \n",
       "674  Recent commercial real estate transactions in ...   \n",
       "879  Skeptical reporting has still been too favorable.   \n",
       "307  The episode of “Patriot Act With Hasan Minhaj,...   \n",
       "357  This word has appeared in 10 articles on NYTim...   \n",
       "\n",
       "                                         Main Headline  \\\n",
       "977  Another Season Comes and Goes While Pac-12 Str...   \n",
       "674         Recent Commercial Real Estate Transactions   \n",
       "879    The Trump Tax Cut: Even Worse Than You’ve Heard   \n",
       "307  Netflix Blocks Show in Saudi Arabia Critical o...   \n",
       "357                                  Word + Quiz: agog   \n",
       "\n",
       "                                        Print Headline  Seo Headline  \n",
       "977               A Power Conference’s Declining Clout           NaN  \n",
       "674                                       Transactions           NaN  \n",
       "879    The Trump Tax Cut: Even Worse Than You’ve Heard           NaN  \n",
       "307  Netflix Blocks Show in Saudi Arabia Critical o...           NaN  \n",
       "357                                  Word + Quiz: agog           NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main_data = pd.read_csv('../../business_news.csv')\n",
    "# main_data = pd.read_csv('../../entrepreneurs_news.csv')\n",
    "# main_data = pd.read_csv('../../financial_news.csv')\n",
    "\n",
    "main_data = main_data.sort_values(by = \"Published\")\n",
    "\n",
    "news_data = main_data[[\"Snippet\", \"Lead Paragraph\", \"Main Headline\"]]\n",
    "news_data.apply(str)\n",
    "main_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Underperforming media deals have left the conference falling behind its peers off the field. That might be the root of its problems on it.', 'Underperforming media deals have left the conference falling behind its peers off the field. That might be the root of its problems on it.', 'Another Season Comes and Goes While Pac-12 Struggles to Keep Up']\n"
     ]
    }
   ],
   "source": [
    "def list_prep(rows_to_list):\n",
    "    news_list = rows_to_list.values.tolist()\n",
    "    return(news_list)\n",
    "    \n",
    "list_of_lists = list_prep(news_data)\n",
    "print(list_of_lists[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['underperforming', 'media', 'deals', 'left', 'conference', 'falling', 'behind', 'peers', 'field', 'might', 'root', 'problems', 'underperforming', 'media', 'deals', 'left', 'conference', 'falling', 'behind', 'peers', 'field', 'might', 'root', 'problems', 'another', 'season', 'comes', 'goes', 'struggles', 'keep']\n"
     ]
    }
   ],
   "source": [
    "def word_prep(list_lists):\n",
    "    big_string = \"\"\n",
    "\n",
    "    for title in list_lists:\n",
    "    #     Splitting titles into list of words\n",
    "        variable = title.split(\" \")\n",
    "    #     print(variable)\n",
    "\n",
    "    #     v = words\n",
    "    #     variable = list of words\n",
    "        for v in variable:\n",
    "            big_string = big_string + \" \" + v\n",
    "\n",
    "    #     big_title_string = ' '.join((str(v) for v in variable))\n",
    "\n",
    "    tokens = word_tokenize(big_string)\n",
    "\n",
    "    # Remove non-alphabetic tokens, such as punctuation\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Filter out stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "\n",
    "    return(words)\n",
    "\n",
    "\n",
    "    # print(tokens)\n",
    "word_list = []\n",
    "for list in list_of_lists:\n",
    "    words = word_prep(list)\n",
    "    word_list.append(words)\n",
    "print(word_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load word2vec model (trained on an enormous Google corpus)\n",
    "model = gensim.models.KeyedVectors.\\\n",
    "load_word2vec_format('../resources/model/GoogleNews-vectors-negative300.bin', binary = True) \n",
    "\n",
    "# Check dimension of word vectors\n",
    "model.vector_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_2_vec(words):\n",
    "    vector_list = []\n",
    "    words_filtered = []\n",
    "    # Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "    vector_list.extend([model[word] for word in words if word in model.vocab])\n",
    "#     return(vector_list)\n",
    "    # Create a list of the words corresponding to these vectors\n",
    "    words_filtered.extend([word for word in words if word in model.vocab])\n",
    "#     return(words_filtered)\n",
    "    # Zip the words together with their vector representations\n",
    "    word_vec_zip = zip(words_filtered, vector_list)\n",
    "    \n",
    "    # Cast to a dict so we can turn it into a dataframe\n",
    "    word_vec_dict = dict(word_vec_zip)\n",
    "    return(word_vec_dict)\n",
    "    \n",
    "\n",
    "\n",
    "dataframe_dict_list = []\n",
    "for list in word_list:\n",
    "    df = word_2_vec(list)\n",
    "    dataframe_dict_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>underperforming</th>\n",
       "      <th>media</th>\n",
       "      <th>deals</th>\n",
       "      <th>left</th>\n",
       "      <th>conference</th>\n",
       "      <th>falling</th>\n",
       "      <th>behind</th>\n",
       "      <th>peers</th>\n",
       "      <th>field</th>\n",
       "      <th>might</th>\n",
       "      <th>root</th>\n",
       "      <th>problems</th>\n",
       "      <th>another</th>\n",
       "      <th>season</th>\n",
       "      <th>comes</th>\n",
       "      <th>goes</th>\n",
       "      <th>struggles</th>\n",
       "      <th>keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166992</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.233398</td>\n",
       "      <td>-0.146484</td>\n",
       "      <td>-0.085449</td>\n",
       "      <td>0.125977</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>-0.294922</td>\n",
       "      <td>0.227539</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.023560</td>\n",
       "      <td>0.194336</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.090332</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.060547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238281</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>0.241211</td>\n",
       "      <td>-0.014709</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.243164</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>-0.019653</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>-0.012939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291016</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.088379</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>-0.159180</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>-0.061768</td>\n",
       "      <td>-0.208008</td>\n",
       "      <td>-0.108887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.107422</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>-0.022827</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>-0.292969</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.104492</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>-0.029419</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.143555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.135742</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>-0.055664</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>-0.106445</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>-0.161133</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>-0.236328</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>-0.083984</td>\n",
       "      <td>-0.013184</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>-0.087402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   underperforming     media     deals      left  conference   falling  \\\n",
       "0        -0.166992  0.097656  0.105957  0.233398   -0.146484 -0.085449   \n",
       "1         0.238281 -0.009277  0.337891  0.073242    0.118164  0.241211   \n",
       "2         0.291016 -0.267578 -0.088379  0.044434    0.242188 -0.116211   \n",
       "3        -0.107422 -0.281250 -0.022827 -0.010254   -0.076660 -0.001678   \n",
       "4        -0.135742  0.016113  0.028809 -0.055664    0.062988 -0.033691   \n",
       "\n",
       "     behind     peers     field     might      root  problems   another  \\\n",
       "0  0.125977 -0.275391 -0.294922  0.227539 -0.116211 -0.023560  0.194336   \n",
       "1 -0.014709  0.074707  0.146484  0.120117  0.243164  0.163086 -0.019653   \n",
       "2  0.145508 -0.164062  0.123047  0.068359  0.163086 -0.114258  0.091797   \n",
       "3 -0.158203  0.351562 -0.292969  0.324219  0.130859  0.273438  0.104492   \n",
       "4 -0.106445  0.134766  0.034668 -0.161133 -0.527344 -0.236328 -0.071777   \n",
       "\n",
       "     season     comes      goes  struggles      keep  \n",
       "0  0.059814  0.265625  0.090332   0.378906  0.060547  \n",
       "1  0.164062  0.037842  0.148438   0.289062 -0.012939  \n",
       "2 -0.159180  0.069336 -0.061768  -0.208008 -0.108887  \n",
       "3  0.061523 -0.029419  0.059082   0.132812  0.143555  \n",
       "4  0.197266 -0.083984 -0.013184   0.004395 -0.087402  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe_list = []\n",
    "for dataframe in range(len(dataframe_dict_list)):\n",
    "    df = pd.DataFrame.from_dict(dataframe_dict_list[dataframe])\n",
    "    dataframe_list.append(df)\n",
    "# df.shape\n",
    "dataframe_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.040616\n",
      "1    0.129954\n",
      "2   -0.002753\n",
      "3    0.033381\n",
      "4   -0.057427\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "def row_summation(dataframe_list):\n",
    "    summation_list = []\n",
    "    for dataframe in dataframe_list:\n",
    "    #     print(dataframe)\n",
    "        total_columns = len(dataframe.columns)\n",
    "    #     print(total_columns)\n",
    "        sums = dataframe.sum(axis = 1, skipna = True)\n",
    "    #     print(sums)\n",
    "        summation = sums/total_columns\n",
    "        summation_list.append(summation)\n",
    "    return summation_list\n",
    "\n",
    "    \n",
    "summation_series = row_summation(dataframe_list)\n",
    "print(summation_series[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_list = main_data['Published'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01T07:30:05+0000</th>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.129954</td>\n",
       "      <td>-0.002753</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>-0.057427</td>\n",
       "      <td>-0.013980</td>\n",
       "      <td>0.042677</td>\n",
       "      <td>-0.091292</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>0.057339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050925</td>\n",
       "      <td>0.051815</td>\n",
       "      <td>-0.130132</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>-0.025178</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>-0.020338</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01T14:00:04+0000</th>\n",
       "      <td>-0.006548</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>-0.091047</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.058803</td>\n",
       "      <td>-0.076625</td>\n",
       "      <td>-0.049800</td>\n",
       "      <td>-0.061550</td>\n",
       "      <td>0.137486</td>\n",
       "      <td>0.082084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.019948</td>\n",
       "      <td>-0.003523</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>-0.006598</td>\n",
       "      <td>-0.036187</td>\n",
       "      <td>-0.053292</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.105887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01T17:47:14+0000</th>\n",
       "      <td>0.051382</td>\n",
       "      <td>0.038457</td>\n",
       "      <td>-0.040468</td>\n",
       "      <td>0.091321</td>\n",
       "      <td>-0.105566</td>\n",
       "      <td>0.050043</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.221899</td>\n",
       "      <td>0.109424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018445</td>\n",
       "      <td>0.025484</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>-0.013770</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.026877</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.094012</td>\n",
       "      <td>-0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01T21:21:40+0000</th>\n",
       "      <td>-0.027873</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.052103</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>-0.090712</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>-0.041097</td>\n",
       "      <td>0.083566</td>\n",
       "      <td>0.067819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020653</td>\n",
       "      <td>-0.104341</td>\n",
       "      <td>-0.046093</td>\n",
       "      <td>-0.068028</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>-0.013541</td>\n",
       "      <td>-0.066595</td>\n",
       "      <td>0.059064</td>\n",
       "      <td>0.035169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02T07:00:00+0000</th>\n",
       "      <td>0.144113</td>\n",
       "      <td>0.129674</td>\n",
       "      <td>-0.027830</td>\n",
       "      <td>0.098580</td>\n",
       "      <td>-0.037144</td>\n",
       "      <td>-0.040632</td>\n",
       "      <td>0.109305</td>\n",
       "      <td>-0.168248</td>\n",
       "      <td>0.135254</td>\n",
       "      <td>0.042855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019758</td>\n",
       "      <td>-0.118478</td>\n",
       "      <td>-0.038942</td>\n",
       "      <td>-0.057478</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>-0.200335</td>\n",
       "      <td>-0.007311</td>\n",
       "      <td>-0.116525</td>\n",
       "      <td>-0.052213</td>\n",
       "      <td>-0.024972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1         2         3         4    \\\n",
       "2019-01-01T07:30:05+0000  0.040616  0.129954 -0.002753  0.033381 -0.057427   \n",
       "2019-01-01T14:00:04+0000 -0.006548  0.075945 -0.091047  0.003771  0.058803   \n",
       "2019-01-01T17:47:14+0000  0.051382  0.038457 -0.040468  0.091321 -0.105566   \n",
       "2019-01-01T21:21:40+0000 -0.027873  0.047825  0.052103  0.020469 -0.090712   \n",
       "2019-01-02T07:00:00+0000  0.144113  0.129674 -0.027830  0.098580 -0.037144   \n",
       "\n",
       "                               5         6         7         8         9    \\\n",
       "2019-01-01T07:30:05+0000 -0.013980  0.042677 -0.091292  0.117317  0.057339   \n",
       "2019-01-01T14:00:04+0000 -0.076625 -0.049800 -0.061550  0.137486  0.082084   \n",
       "2019-01-01T17:47:14+0000  0.050043  0.067348  0.034418  0.221899  0.109424   \n",
       "2019-01-01T21:21:40+0000  0.011233  0.030041 -0.041097  0.083566  0.067819   \n",
       "2019-01-02T07:00:00+0000 -0.040632  0.109305 -0.168248  0.135254  0.042855   \n",
       "\n",
       "                            ...          290       291       292       293  \\\n",
       "2019-01-01T07:30:05+0000    ...    -0.050925  0.051815 -0.130132  0.007858   \n",
       "2019-01-01T14:00:04+0000    ...    -0.053502  0.019948 -0.003523  0.008057   \n",
       "2019-01-01T17:47:14+0000    ...     0.018445  0.025484  0.005743  0.020642   \n",
       "2019-01-01T21:21:40+0000    ...    -0.020653 -0.104341 -0.046093 -0.068028   \n",
       "2019-01-02T07:00:00+0000    ...     0.019758 -0.118478 -0.038942 -0.057478   \n",
       "\n",
       "                               294       295       296       297       298  \\\n",
       "2019-01-01T07:30:05+0000 -0.025178  0.005754  0.025302 -0.020338  0.020962   \n",
       "2019-01-01T14:00:04+0000  0.019845 -0.006598 -0.036187 -0.053292 -0.040545   \n",
       "2019-01-01T17:47:14+0000 -0.013770 -0.054761 -0.026877 -0.051270  0.094012   \n",
       "2019-01-01T21:21:40+0000 -0.011126  0.021588 -0.013541 -0.066595  0.059064   \n",
       "2019-01-02T07:00:00+0000  0.082912 -0.200335 -0.007311 -0.116525 -0.052213   \n",
       "\n",
       "                               299  \n",
       "2019-01-01T07:30:05+0000  0.002306  \n",
       "2019-01-01T14:00:04+0000 -0.105887  \n",
       "2019-01-01T17:47:14+0000 -0.003528  \n",
       "2019-01-01T21:21:40+0000  0.035169  \n",
       "2019-01-02T07:00:00+0000 -0.024972  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation_dict = {}\n",
    "published_index = 0\n",
    "for series in summation_series:\n",
    "    summation_dict.update({published_list[published_index]: series})\n",
    "    published_index += 1\n",
    "    \n",
    "summation_df = pd.DataFrame(summation_dict)\n",
    "summation_df = summation_df.T\n",
    "summation_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_df.to_csv(\"../resources/news/financial_news_word2vec.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
